# Trabajo Pr√°ctico - Aprendizaje Autom√°tico II
Este repositorio contiene la soluci√≥n a tres problemas propuestos
en el Trabajo Pr√°ctico N¬∞1 de la materia Aprendizaje Autom√°tico II.
Abarca t√©cnicas de regresi√≥n con redes neuronales, clasificaci√≥n de gestos con MediaPipe y redes densas,
y clasificaci√≥n de im√°genes usando redes convolucionales y transfer learning.

## üñã Autores
Herrera Morena, Nardi Gianella, Zorzolo Rubio Juana

## üß† Problema 1: Predicci√≥n del Rendimiento Acad√©mico
Descripci√≥n:
Se utiliz√≥ un conjunto de datos que incluye informaci√≥n sobre h√°bitos de estudio y estilo de vida de estudiantes universitarios para predecir su rendimiento acad√©mico (√≠ndice de rendimiento) utilizando un modelo de regresi√≥n basado en redes neuronales.

Variables del dataset:

- Hours Studied
- Previous Scores
- Extracurricular Activities
- Sleep Hours
- Sample Question Papers Practiced

Variable objetivo:
- Performance Index (rango de 10 a 100)

Objetivo:
- Construir un modelo de regresi√≥n con redes neuronales capaz de predecir el Performance Index.

Contenido entregado:

- An√°lisis exploratorio y preprocesamiento de los datos.
- Entrenamiento del modelo con validaci√≥n.
- Evaluaci√≥n del desempe√±o con m√©tricas de regresi√≥n.
- Visualizaciones de resultados.

Ubicaci√≥n:

üìÑ AA2 - TP1.ipynb (Colab Notebook)

## ‚úã Problema 2: Clasificaci√≥n de Gestos con MediaPipe
Descripci√≥n:
Sistema para reconocer gestos de "piedra", "papel" y "tijeras" usando detecci√≥n de manos con MediaPipe y una red neuronal densa.

Etapas:

- record-dataset.py: Captura de datos usando webcam y MediaPipe. Guarda coordenadas de landmarks en archivos .npy.
- train-gesture-classifier.py: Entrenamiento de un modelo denso con las coordenadas.
- rock-paper-scissors.py: Prueba en tiempo real del modelo con webcam.

Objetivo:
- Entrenar un clasificador capaz de identificar correctamente el gesto de la mano basado en los landmarks de MediaPipe.

Contenido entregado:

- 3 scripts funcionales en Python.
- Im√°genes que demuestran el funcionamiento del sistema.
- Modelo entrenado (.h5).
- C√≥digo comentado.

Ubicaci√≥n:

üìÅ scripts_python

## üåç Problema 3: Clasificaci√≥n de Escenas Naturales con CNN
Descripci√≥n:
Se trabaj√≥ con un dataset de aproximadamente 14.000 im√°genes de escenas naturales clasificadas en seis categor√≠as:

- buildings
- forest
- glacier
- mountain
- sea
- street

Objetivo:

Construir varios modelos de clasificaci√≥n de im√°genes:

- Modelo con capas densas.
- Modelo con capas convolucionales + densas.
- Modelo con bloques residuales (identidad).
- Modelo con transfer learning usando un backbone de tf.keras.applications.

Contenido entregado:

- Preprocesamiento de im√°genes.
- Implementaci√≥n y entrenamiento de los 4 modelos.
- Evaluaci√≥n de desempe√±o con m√©tricas y visualizaciones.
- Comparaci√≥n entre arquitecturas.

Ubicaci√≥n:

üìÑ AA2 - TP1.ipynb (Colab Notebook)

## üìÅ Estructura del Repositorio

AA2 - TP1.ipynb # Notebook con la soluci√≥n de los problemas 1 y 3 (Rendimiento Acad√©mico y Clasificaci√≥n de Escenas Naturales).

scripts_python/

record-dataset.py # Script para grabar el dataset de gestos usando MediaPipe.

train-gesture-classifier.py # Script para entrenar el clasificador de gestos.

rock-paper-scissors.py # Script para probar el sistema de clasificaci√≥n de gestos en tiempo real.

im√°genes/

... # Im√°genes que muestran el funcionamiento del sistema de clasificaci√≥n de gestos.

... # Ejemplos de im√°genes procesadas en la clasificaci√≥n de escenas naturales.

## üìù Instrucciones de Ejecuci√≥n

### Ejercicio 1 y 3 - Predicci√≥n del Rendimiento Acad√©mico y Clasificaci√≥n de Escenas Naturales
1. Accede al archivo **AA2 - TP1.ipynb** en Google Colab.
2. Sube los datasets correspondientes al entorno de Google Colab.
3. Ejecuta las celdas en orden para realizar el an√°lisis, entrenamiento del modelo y evaluaci√≥n.
4. Las visualizaciones y resultados de las m√©tricas de desempe√±o se generar√°n autom√°ticamente.

### Ejercicio 2 - Clasificaci√≥n de Gestos con MediaPipe
1. Para grabar el dataset de gestos:
   - Ejecuta el script **record-dataset.py** para capturar im√°genes de la c√°mara y guardar las coordenadas de los landmarks.
   - Las coordenadas se guardar√°n en archivos `.npy` (por ejemplo, `rps_dataset.npy` y `rps_labels.npy`).
2. Para entrenar el modelo:
   - Ejecuta el script **train-gesture-classifier.py** para entrenar el modelo con los datos grabados.
   - El modelo entrenado se guardar√° en un archivo `.h5` (por ejemplo, `rps_model.h5`).
3. Para probar el sistema:
   - Ejecuta el script **rock-paper-scissors.py** para realizar la clasificaci√≥n de gestos en tiempo real.
   - El modelo predecir√° y mostrar√° el gesto de la mano (piedra, papel o tijeras) en pantalla.

## üìö Requisitos

- Python 3.x
- TensorFlow 2.x
- MediaPipe
- NumPy
- Matplotlib (para visualizaci√≥n de resultados)
- OpenCV (para captura de video)

Instalaci√≥n de dependencias:

```bash
pip install tensorflow mediapipe numpy matplotlib opencv-python
